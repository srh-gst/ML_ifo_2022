{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions for Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_right\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./olympics.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = df.drop(\"score\", axis=1).values\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42).fit(X_scaled)\n",
    "pca = PCA().fit(X_scaled)\n",
    "out = pd.DataFrame(pca.components_, columns=df.columns[:-1])\n",
    "df.index += 1\n",
    "out.index.name = \"Component\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(out, cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulated = pca.explained_variance_ratio_.cumsum()\n",
    "THRES = 0.9\n",
    "n_components = bisect_right(cumulated, THRES) + 1\n",
    "print(f\"You need {n_components} components to explain at least {THRES:.0%} of the variance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42).fit(X_scaled)\n",
    "agg = AgglomerativeClustering(n_clusters=k).fit(X_scaled)\n",
    "dbscan = DBSCAN(min_samples=2, eps=1).fit(X_scaled)\n",
    "out = pd.DataFrame({\"kmeans\": kmeans.labels_,\n",
    "                    \"agglomerative\": agg.labels_,\n",
    "                    \"DBSCAN\": dbscan.labels_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"K-Means: {silhouette_score(X_scaled, kmeans.labels_):.3f}\")\n",
    "print(f\"Agglomerative clustering: {silhouette_score(X_scaled, agg.labels_):.3f}\")\n",
    "mask = dbscan.labels_ > -1\n",
    "print(f\"DBSCAN: {silhouette_score(X_scaled[mask], dbscan.labels_[mask]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = pd.DataFrame(X.T[1:3].T, columns=iris[\"feature_names\"][1:3])\n",
    "out = pd.concat([out, add], axis=1, sort=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"DBSCAN\"] = out[\"DBSCAN\"].replace(-1, \"Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.melt(id_vars=iris[\"feature_names\"][1:3],\n",
    "               var_name=\"Cluster algorithm\", value_name=\"assignment\")\n",
    "sns.catplot(x=\"sepal width (cm)\", y=\"petal length (cm)\",\n",
    "            col=\"Cluster algorithm\", hue=\"assignment\", data=out)\n",
    "plt.savefig(Path(\"./output/cluster_petal.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
